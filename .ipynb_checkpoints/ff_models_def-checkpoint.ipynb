{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73e9a129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "from itertools import combinations\n",
    "import torch\n",
    "import math \n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "%run r3b_clustering_def.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e26ff07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class two_hidden_layer_model(nn.Module):\n",
    "        def __init__(self,in_features,nodes,hidden_nodes):\n",
    "                super().__init__()\n",
    "                self.linear = torch.nn.Linear(in_features,nodes)\n",
    "                self.another_linear = torch.nn.Linear(nodes,hidden_nodes)\n",
    "                self.another_linear_two = torch.nn.Linear(hidden_nodes,hidden_nodes)\n",
    "                self.activation = torch.nn.ReLU()\n",
    "                self.linear_back = torch.nn.Linear(hidden_nodes,1)\n",
    "\n",
    "        def forward(self, x):\n",
    "                output_tensor = self.linear(x)\n",
    "                #output_tensor = self.another_linear(output_tensor)\n",
    "                output_tensor = self.activation(output_tensor)\n",
    "                output_tensor = self.another_linear(output_tensor)\n",
    "                output_tensor = self.another_linear_two(output_tensor)\n",
    "                output_tensor = self.linear_back(output_tensor)\n",
    "                output_tensor = torch.sigmoid(output_tensor)\n",
    "                output_tensor = torch.squeeze(output_tensor)\n",
    "                return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b56569d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_two_hidden_model(input_data,true_data,in_features,features,learning_rate,hidden_features):\n",
    "    n_epochs = 10000\n",
    "    #for uniform energy use n_epochs x 5\n",
    "    #n_epochs = 50000\n",
    "    model = two_hidden_layer_model(in_features,features,hidden_features)\n",
    "    print(\"Model's state_dict:\")\n",
    "    for param_tensor in model.state_dict():\n",
    "        print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "    loss_fn = nn.BCELoss()  # binary cross entropy\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    model.train()\n",
    "    loss_val = []\n",
    "    for epoch in range(n_epochs):\n",
    "        print(\"epochnr:\",epoch,(float(epoch)/float(n_epochs))*100,\"%\")\n",
    "        y_pred = model(input_data)\n",
    "        y_true = true_data\n",
    "        loss = loss_fn(y_pred,y_true)\n",
    "        loss_val.append(loss.detach().item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #print(f'Finished epoch {epoch}, latest loss {loss}')\n",
    "    ##TJ just uncomment this line for now...\n",
    "    #plt.plot(loss_val)\n",
    "    print(\"this is latest loss val:\\t\",loss_val[-1])\n",
    "    #torch.save(model,\"ff_scripted.pth\")\n",
    "    torch.save(model.state_dict(),\"ff_scripted.pth\")\n",
    "    with torch.no_grad():\n",
    "        print(\"hello I am inside no grad\")\n",
    "        model.load_state_dict(torch.load(\"ff_scripted.pth\", weights_only=True))\n",
    "        #model = torch.load(\"ff_scripted.pth\")\n",
    "        model.eval()\n",
    "    eval_pred = model(input_data).detach().numpy()\n",
    "    return eval_pred,loss_val[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e7ac8c8-1f31-44d0-832f-86825d8dacb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_two_hidden_model(input_data,true_data,in_features,features,learning_rate,hidden_features):\n",
    "    model = two_hidden_layer_model(in_features,features,hidden_features)\n",
    "    loss_fn = nn.BCELoss()  # binary cross entropy\n",
    "    file_path = \"ff_scripted.pth\"\n",
    "    model.load_state_dict(torch.load(file_path, weights_only=True))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(input_data)\n",
    "        y_true = true_data\n",
    "        loss = loss_fn(y_pred,y_true)\n",
    "        eval_pred = model(input_data).detach().numpy()\n",
    "    return eval_pred,loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d21fa1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manip_data_ff(data,features):\n",
    "    ll = []\n",
    "    true_vals = []\n",
    "    for i in range(0,int(np.max(data,axis=0)[0]+1)-(int(np.max(data,axis=0)[0]+1)%3) ,3):\n",
    "    #for i in range(0,int(np.max(data,axis=0)[0])-(int(np.max(data,axis=0)[0])%3) ,3):\n",
    "        mask = ((data[:,0] == i) | (data[:,0] == i+1) | (data[:,0] == i+2))\n",
    "        evt = data[mask]\n",
    "        pair_indices = list(combinations(range(evt.shape[0]), 2))\n",
    "        for i, (idx1, idx2) in enumerate(pair_indices):\n",
    "            l = []\n",
    "            ### this is the new stuff....\n",
    "            time_diff = abs(evt[idx1,4]-evt[idx2,4])\n",
    "            ene_diff = abs(evt[idx1,1]-evt[idx2,1])\n",
    "            min_theta = evt[idx1,2] if evt[idx2,2] > evt[idx1,2] else evt[idx2,2]\n",
    "            max_theta = evt[idx2,2] if evt[idx2,2] > evt[idx1,2] else evt[idx1,2]\n",
    "            theta_diff = abs(max_theta-min_theta) if (abs(max_theta-min_theta) < abs(max_theta-(min_theta+math.pi))) else abs(max_theta-(min_theta+math.pi)) \n",
    "            min_phi = evt[idx1,3] if evt[idx2,3] > evt[idx1,3] else evt[idx2,3]\n",
    "            max_phi = evt[idx2,3] if evt[idx2,3] > evt[idx1,3] else evt[idx1,3]\n",
    "            phi_diff = abs(max_phi-min_phi) if (abs(max_phi-min_phi) < abs(max_phi-(min_phi+math.pi))) else abs(max_phi-(min_phi+math.pi))\n",
    "            diff_arr = np.array([ene_diff,theta_diff,phi_diff,time_diff])\n",
    "            ###following lines I may can remove, only test, or?!?\n",
    "            test_np = np.concatenate((evt[idx1,1:],evt[idx2,1:]))\n",
    "            test_np = np.concatenate((test_np,diff_arr))\n",
    "            ##this is if I also want to add up the sum of the values\n",
    "            time_sum = abs(evt[idx1,4] + evt[idx2,4])\n",
    "            ene_sum = abs(evt[idx1,1] + evt[idx2,1])\n",
    "            theta_sum = abs(evt[idx1,2] + evt[idx2,2])\n",
    "            sum_arr = np.array([ene_sum,theta_sum,time_sum])\n",
    "            if (features == 8):\n",
    "                l.append(np.concatenate((evt[idx1,1:],evt[idx2,1:])))\n",
    "            if (features == 12):\n",
    "                l.append(np.concatenate((evt[idx1,1:],evt[idx2,1:],diff_arr)))\n",
    "            if (features == 15):\n",
    "                l.append(np.concatenate((evt[idx1,1:],evt[idx2,1:],diff_arr,sum_arr)))\n",
    "            \n",
    "            #l.append(np.concatenate((evt[idx1,1:],evt[idx2,1:],diff_arr)))\n",
    "            ### end of new stuff\n",
    "            #l.append(np.concatenate((evt[idx1,1:],evt[idx2,1:])))\n",
    "            ll.append(l)\n",
    "    \n",
    "    #print(ll)\n",
    "    input_data = torch.FloatTensor(ll)\n",
    "    input_data = torch.squeeze(input_data)\n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d310c6b8-81ac-4789-a45d-ca96190c7737",
   "metadata": {},
   "source": [
    "### --- this was old part, just comment out for now ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ba151f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #data = genfromtxt('small_file_correct_coord.txt', delimiter=',')\n",
    "# data = genfromtxt('test_output_false_negative.txt', delimiter=',') \n",
    "# #data = genfromtxt('small_file.txt', delimiter=',')\n",
    "# #data = genfromtxt('raw_data_test.txt',delimiter=',') ## raw not preclustered data\n",
    "# data[:,4] =(data[:,4]-np.min(data[:,4]))/(np.max(data[:,4])-np.min(data[:,4]))\n",
    "# unique_values, continuous_numbers = np.unique(data[:,0], return_inverse=True)\n",
    "# data[:,0] = continuous_numbers\n",
    "# data[:,2] = data[:,2]*math.pi/180.\n",
    "# data[:,3] = data[:,3]*math.pi/180.\n",
    "# ###TJ test if you are also better without using the time diff\n",
    "# #data[:,4] = 1\n",
    "\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82168f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# foo_comb = get_true_combinatorics(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "129cf6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data = manip_data_ff(data,12)\n",
    "# print(\"data size:\",input_data.shape)\n",
    "# print(\"true size:\",len(foo_comb))\n",
    "# eval_pred_h2 = train_two_hidden_model(input_data,torch.FloatTensor(foo_comb),12,1000,5e-3,100)\n",
    "\n",
    "\n",
    "# print(\"data size:\",eval_pred_h2[0].shape )\n",
    "# print(\"true_size:\",len(foo_comb))\n",
    "# foo_ene = get_true_reco_ene(data,eval_pred_h2[0].tolist(),foo_comb)\n",
    "\n",
    "# ##validation\n",
    "# #validation_output = validate_two_hidden_model(input_data,torch.FloatTensor(foo_comb),12,1000,5e-3,100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0424db53-2586-4747-bea0-b8300ad2fbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation_output = validate_two_hidden_model(input_data,torch.FloatTensor(foo_comb),12,1000,5e-3,100)\n",
    "# valid_ene = get_true_reco_ene(data,validation_output[0].tolist(),foo_comb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c51cda36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pred_binaries = eval_pred_h2[0]\n",
    "# print(pred_binaries)\n",
    "\n",
    "# plt.hist(pred_binaries[np.array(foo_comb) == True],bins=100,range=(0,1),label=\"belonging together\",color=\"red\",alpha=0.5)\n",
    "# plt.hist(pred_binaries[np.array(foo_comb) == False],bins=100,range=(0,1),label=\"independent\",color=\"blue\",alpha=0.5)\n",
    "# plt.yscale(\"log\")\n",
    "# plt.grid()\n",
    "# plt.legend()\n",
    "# plt.savefig(\"pred_multi_layer_stuff.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1be77f-984b-4e5e-bc04-cac048e55c4b",
   "metadata": {},
   "source": [
    "### --- end of commenting out ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d37a353-c148-40e6-80c1-8e3c2cd5475b",
   "metadata": {},
   "source": [
    "### training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17485f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #training_data = genfromtxt('training_all_output_false_negative.txt', delimiter=',')\n",
    "# training_data = genfromtxt('training_raw.txt', delimiter=',')\n",
    "# ##training on raw data with uniform energy distribution between 0.3 MeV and 10 MeV\n",
    "# #training_data = genfromtxt('data_raw_uniform_training.csv', delimiter=',')\n",
    "# ## some data manipulation needed\n",
    "# training_data[:,4] =(training_data[:,4]-np.min(training_data[:,4]))/(np.max(training_data[:,4])-np.min(training_data[:,4]))\n",
    "# unique_values, continuous_numbers = np.unique(training_data[:,0], return_inverse=True)\n",
    "# training_data[:,0] = continuous_numbers\n",
    "# training_data[:,2] = training_data[:,2]*math.pi/180.\n",
    "# training_data[:,3] = training_data[:,3]*math.pi/180.\n",
    "# #training_data[:,4] = 1  ## set time to 1, not sensitive to time, TODO: remove later, just a test\n",
    "# training_true = get_true_combinatorics(training_data)\n",
    "# input_training_data = manip_data_ff(training_data,12) ##second param gives number of features\n",
    "\n",
    "# pred_training = train_two_hidden_model(input_training_data,torch.FloatTensor(training_true),12,1000,5e-3,100)\n",
    "\n",
    "# training_reco = get_true_reco_ene(training_data,pred_training[0].tolist(),training_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd0633df-d06c-4f1d-9773-acb3ca16b7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# foo_pred = pred_training[0]\n",
    "\n",
    "# # test_pred = foo_pred[:10]\n",
    "# # test_true = np.array(training_true[:10])\n",
    "# # print(test_pred)\n",
    "# # print(test_true)\n",
    "# # print(test_pred[test_true == True])\n",
    "# #training_true = np.array(training_true)\n",
    "# plt.hist(foo_pred[training_true == True],bins=100,range=(0,1),label=\"belonging together\",color=\"red\",alpha=0.5)\n",
    "# plt.hist(foo_pred[training_true == False],bins=100,range=(0,1),label=\"independent\",color=\"blue\",alpha=0.5)\n",
    "# plt.yscale('log')\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fa18e8-9058-415f-88fb-0c1875511f38",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc4c704-2691-4bfc-8f99-66458a6ad7ab",
   "metadata": {},
   "source": [
    "### validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14591d3d-64a6-49fe-85e0-898343945da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #val_data = genfromtxt('validation_all_output_false_negative.txt', delimiter=',')\n",
    "# val_data = genfromtxt('validation_raw.txt', delimiter=',')\n",
    "# ##test on raw data with uniform energy distribution from 0.3MeV to 10MeV\n",
    "# #val_data = genfromtxt('data_raw_uniform_test.csv', delimiter=',')\n",
    "# ## some data manipulation needed\n",
    "# val_data[:,4] =(val_data[:,4]-np.min(val_data[:,4]))/(np.max(val_data[:,4])-np.min(val_data[:,4]))\n",
    "# unique_values, continuous_numbers = np.unique(val_data[:,0], return_inverse=True)\n",
    "# val_data[:,0] = continuous_numbers\n",
    "# val_data[:,2] = val_data[:,2]*math.pi/180.\n",
    "# val_data[:,3] = val_data[:,3]*math.pi/180.\n",
    "# #val_data[:,4] = 1 ## set time to 1, not sensitive to time, TODO: remove later, just a test\n",
    "# val_true = get_true_combinatorics(val_data)\n",
    "# input_val_data = manip_data_ff(val_data,12) ##second param gives number of features\n",
    "\n",
    "# pred_val = validate_two_hidden_model(input_val_data,torch.FloatTensor(val_true),12,1000,5e-3,100)\n",
    "\n",
    "# val_reco = get_true_reco_ene(val_data,pred_val[0].tolist(),val_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f31341d-7678-4329-94bf-6720ff63e039",
   "metadata": {},
   "source": [
    "#### just test to subsract bin counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d65a502-e5b6-408d-a186-390d9aab7468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist1, bins1 = np.histogram(val_reco[0], bins=np.linspace(0, 10, 100))\n",
    "# hist2, bins2 = np.histogram(val_reco[1], bins=np.linspace(0, 10, 100))\n",
    "# residual = (hist1 - hist2)\n",
    "# a = np.arange(0,9.9,0.1)\n",
    "# print(a)\n",
    "# print(a.shape)\n",
    "# print(residual.shape)\n",
    "# plt.hist(a,100, weights=residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adb847a-8570-4423-8f26-a2df43f48c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

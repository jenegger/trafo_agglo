{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "333978a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "from itertools import combinations\n",
    "import torch\n",
    "import math \n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a11a456-0ba4-4b57-8dd9-eea09f6c588f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def angle_btw_hits(arr1,arr2):\n",
    "    theta1 = arr1[2]\n",
    "    theta2 = arr2[2]\n",
    "    phi1 = arr1[3]\n",
    "    phi2 = arr2[3]\n",
    "    opang = math.acos(math.sin(theta1)*math.sin(theta2)*math.cos(phi1-phi2)+math.cos(theta1)*math.cos(theta2))\n",
    "    return opang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bb8fca7-5037-4a7e-a03d-a67656e851a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(xss):\n",
    "    return [x for xs in xss for x in xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "384a3164-4a05-4b4b-8339-fad624f00365",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_r3b_clustering(data,clustersize):\n",
    "    print(data.shape)\n",
    "    array_unique_events = np.unique(data[:,0])\n",
    "    print(array_unique_events)\n",
    "    all_pred = []\n",
    "    for i in range(0,int(np.max(data,axis=0)[0]+1)-(int(np.max(data,axis=0)[0]+1)%3) ,3):\n",
    "    #for i in range(0,int(np.max(data,axis=0)[0])-(int(np.max(data,axis=0)[0])%3) ,3):\n",
    "        evt = data[data[:,0] == array_unique_events[i]]\n",
    "        evt = np.vstack((evt,data[data[:,0] == array_unique_events[i+1]]))\n",
    "        evt = np.vstack((evt,data[data[:,0] == array_unique_events[i+2]]))\n",
    "        nr_hits = evt.shape[0]\n",
    "        hitnr = np.array([x for x in range(evt.shape[0])])\n",
    "        hitnr = np.transpose(hitnr)\n",
    "        hitnr = hitnr.reshape(-1, 1)\n",
    "        evt = np.hstack((evt,hitnr))\n",
    "        # sort along the energy\n",
    "        evt = evt[evt[:, 1].argsort()[::-1]]\n",
    "        #now check opening angle between the hits\n",
    "        cluster_list = []\n",
    "        while(evt.shape[0]):\n",
    "            v_temp = []\n",
    "            l = []\n",
    "            for i in range(evt.shape[0]):\n",
    "                if (i == 0):\n",
    "                    l.append(evt[0,5].astype(int))\n",
    "                else:\n",
    "                    #calculate angle\n",
    "                    angle = angle_btw_hits(evt[0,:],evt[i,:])\n",
    "                    if (angle < clustersize):\n",
    "                        l.append(evt[i,5].astype(int))\n",
    "                    else:\n",
    "                        v_temp.append(evt[i,:])\n",
    "            l.sort()\n",
    "            cluster_list.append(l)\n",
    "            evt = np.array(v_temp)\n",
    "        #compress list of clusters, they need at least two entries to be a cluster, otherwise the single hit is treated as cluster\n",
    "        compr_cluster_list = []\n",
    "        for i in range(len(cluster_list)):\n",
    "            if len(cluster_list[i]) > 1:\n",
    "                compr_cluster_list.append(cluster_list[i])\n",
    "            else:\n",
    "                continue\n",
    "        final_pair_list = []\n",
    "        for i in range(len(compr_cluster_list)):\n",
    "            pair_indices = list(combinations(compr_cluster_list[i],2))\n",
    "            final_pair_list.append(pair_indices)\n",
    "        reco_indices = flatten(final_pair_list)\n",
    "        # compare all combinations with all predicted combinations\n",
    "        all_combinations = list(combinations(range(nr_hits), 2))\n",
    "        ## predictions\n",
    "        pred_list = []\n",
    "        for i in range(len(all_combinations)):\n",
    "            pred_value = 0\n",
    "            for j in range(len(reco_indices)):\n",
    "                if (all_combinations[i] == reco_indices[j]):\n",
    "                    #print(type(reco_indices[j]))\n",
    "                    pred_value = 1\n",
    "            pred_list.append(pred_value)\n",
    "            all_pred.append(pred_value)\n",
    "    return all_pred\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa29a3c6-83ad-47a8-9dd0-57571595f046",
   "metadata": {},
   "source": [
    "## now method to plot data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52a149e5-e075-49db-b6cc-ea42f44b940c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_true_reco(data):\n",
    "    energy_spec = []\n",
    "    unique_ind = np.unique(data[:,0])\n",
    "    for i in unique_ind:\n",
    "        ene = np.sum(data[data[:,0] == i,1])\n",
    "        energy_spec.append(ene)\n",
    "\n",
    "    plt.hist(energy_spec,bins=70,range=(0,7))\n",
    "    plt.title(\"True energy spectrum\")\n",
    "    plt.yscale('log')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c203ad7b-fc13-4a08-84fa-f6851945dfcf",
   "metadata": {},
   "source": [
    "### in this section I want to get the true values combination list\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b2b1873-d3eb-4731-aba8-258561f473fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_combinatorics(data):\n",
    "    ll = []\n",
    "    true_vals = []\n",
    "    for i in range(0,int(np.max(data,axis=0)[0]+1)-(int(np.max(data,axis=0)[0]+1)%3) ,3):\n",
    "    #for i in range(0,int(np.max(data,axis=0)[0])-(int(np.max(data,axis=0)[0])%3) ,3):\n",
    "        mask = ((data[:,0] == i) | (data[:,0] == i+1) | (data[:,0] == i+2))\n",
    "        evt = data[mask]\n",
    "        pair_indices = list(combinations(range(evt.shape[0]), 2))\n",
    "        for i, (idx1, idx2) in enumerate(pair_indices):\n",
    "            l = []\n",
    "            if (evt[idx1,0] == evt[idx2,0]):\n",
    "                true_vals.append(1)\n",
    "            else:\n",
    "                true_vals.append(0)\n",
    "    return (true_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd41101-5c5a-4765-9019-6996dbfefa23",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ba74d0f-e447-4cbc-908a-d225e3d9c110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_reco_ene(data,reco_vals,true_vals):\n",
    "    #print(\"reco_vals\",reco_vals)\n",
    "    ene_list = []\n",
    "    ene_true_list = []\n",
    "    idx = 0\n",
    "    well_reco = 0\n",
    "    array_unique_events = np.unique(data[:,0])\n",
    "    nr_events = 0\n",
    "    nr_t = 0\n",
    "    nr_fp = 0\n",
    "    nr_fn = 0\n",
    "    nr_fpfn = 0\n",
    "    for i in range(0,int(np.max(data,axis=0)[0]+1)-(int(np.max(data,axis=0)[0]+1)%3) ,3):\n",
    "    #for i in range(0,int(np.max(data,axis=0)[0])-(int(np.max(data,axis=0)[0])%3) ,3):\n",
    "        nr_events += 1\n",
    "        mask = ((data[:,0] == i) | (data[:,0] == i+1) | (data[:,0] == i+2))\n",
    "        evt = data[mask]\n",
    "        pair_indices = list(combinations(range(evt.shape[0]), 2))\n",
    "        ##pair indices which belong together...\n",
    "        pred_comb = []\n",
    "        ##TJ this is the new part with true stuff\n",
    "        true_comb = []\n",
    "        for m in range(evt.shape[0]):\n",
    "            pred_comb.append((m,m))\n",
    "            true_comb.append((m,m))\n",
    "        for j in range (len(pair_indices)):\n",
    "            #print(\"reco_vals[idx+j]:\\t\", reco_vals[idx+j])\n",
    "            if reco_vals[idx+j] > 0.75:\n",
    "                pred_comb.append(pair_indices[j])\n",
    "            if true_vals[idx+j] > 0.75:   \n",
    "                true_comb.append(pair_indices[j])\n",
    "        G = nx.Graph()\n",
    "        G.add_edges_from(pred_comb)\n",
    "        connected_components = list(nx.connected_components(G))\n",
    "        ##TJ again, this it the addition for the true values\n",
    "        T = nx.Graph()\n",
    "        T.add_edges_from(true_comb)\n",
    "        true_components = list(nx.connected_components(T))\n",
    "        set_true = {frozenset(sublist) for sublist in true_components}\n",
    "        set_pred = {frozenset(sublist) for sublist in connected_components}\n",
    "\n",
    "        evt_type =  check_matrix(set_true,set_pred)\n",
    "        if (evt_type == \"t\"):\n",
    "            nr_t += 1\n",
    "        if (evt_type == \"fp\"):\n",
    "            nr_fp += 1\n",
    "        if (evt_type == \"fn\"):\n",
    "            nr_fn +=1\n",
    "        if (evt_type == \"fpfn\"):\n",
    "            nr_fpfn += 1        \n",
    "        \n",
    "        #print(\"connected components:\\t\", connected_components)        \n",
    "        # Find the intersection of the two sets\n",
    "        common_sublists = set_true.intersection(set_pred)\n",
    "\n",
    "        well_reco += len(common_sublists)\n",
    "        for k in range(len(connected_components)):\n",
    "            columns_to_sum = evt[list(connected_components[k]),1]\n",
    "            ene = np.sum(columns_to_sum)\n",
    "            ene_list.append(ene)\n",
    "        #make list true energy\n",
    "        for l in range(len(true_components)):\n",
    "            true_columns_to_sum = evt[list(true_components[l]),1]\n",
    "            ene_true = np.sum(true_columns_to_sum)\n",
    "            ene_true_list.append(ene_true)\n",
    "        idx += len(pair_indices)\n",
    "    single_hit_energies = []\n",
    "    for i in range(data.shape[0]):\n",
    "        single_hit_energies.append(data[i,1])\n",
    "        \n",
    "    #plt.hist(single_hit_energies,bins=70,range=(0,7),label=\"single hit energy\",color=\"green\",alpha=0.5)    \n",
    "    plt.hist(ene_list,bins=100,range=(0,10),label=\"reconstructed energy\",color=\"red\",alpha=0.3)\n",
    "    plt.grid()\n",
    "    plt.hist(ene_true_list,bins=100,range=(0,10),label=\"true energies\",color=\"blue\",alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.yscale('log')\n",
    "    well_reco = float(well_reco)/float(np.max(data,axis=0)[0])\n",
    "\n",
    "    print(\"well reco...\", well_reco)\n",
    "    print(\"---more statistics....---\")\n",
    "    print(\"fully true_reco_cluster:\\t\", nr_t/nr_events)\n",
    "    print(\"false positive events:\\t\" , nr_fp/nr_events)\n",
    "    print(\"false negative events:\\t\", nr_fn/nr_events)\n",
    "    print(\"mixed false events:\\t\" , nr_fpfn/nr_events)\n",
    "    print(\"end of statistiscs------\")\n",
    "    return (ene_list,ene_true_list,well_reco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4ff4356-9fb1-4c8f-b9c9-df6dccc8910e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #data = genfromtxt('raw_data_test.txt', delimiter=',')\n",
    "# #data = genfromtxt('validation_raw.txt',delimiter=',')\n",
    "# data = genfromtxt('data_raw_uniform_test.csv',delimiter=',')\n",
    "# #data = genfromtxt('data_stream_2121.txt', delimiter=',')\n",
    "# #my_data[:,4] = my_data[:,4]+4500  #this step is needed, I only want positive time values, so that I can use the time as a radius\n",
    "# data[:,4] = 1  #this step is needed, I only want positive time values, so that I can use the time as a radius\n",
    "# # ### structure of mydata : eventnr, energy, theta, phi, hit-time\n",
    "# data = data*[1.,1.,3.14159/180,3.14159/180,1.]\n",
    "# unique_values, continuous_numbers = np.unique(data[:,0], return_inverse=True)\n",
    "# data[:,0] = continuous_numbers\n",
    "# print(\"continuous numbers:\", continuous_numbers)\n",
    "# out_cluster_r3b = run_r3b_clustering(data,0.25)\n",
    "# #foo = plot_true_reco(data)\n",
    "# foo_comb = get_true_combinatorics(data)\n",
    "# foo_ene = get_true_reco_ene(data,out_cluster_r3b,foo_comb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193454e2-b1c4-4b4b-be1f-69216b85be27",
   "metadata": {},
   "source": [
    "### functionality to write clustered data to file\n",
    "#### e.g hit1, hit2, hit3, hit4,\n",
    "#### if hit1, hit2 belong together then rewrite hit1 and hit 2 that they have both summed energy and same theta, phi (from cms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f000adf-ddee-49a1-9a8a-1f717c4a0110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sph2cart(data):\n",
    "    r = data[:,1]\n",
    "    rsin_theta = r*np.sin(data[:,2])\n",
    "    x = rsin_theta*np.cos(data[:,3])\n",
    "    y = rsin_theta*np.sin(data[:,3])\n",
    "    z = r*np.cos(data[:,2])\n",
    "    cart_data = np.array([data[:,0],data[:,1],x,y,z,data[:,4]]).T\n",
    "    #return np.array([data[:,0],data[:,1],x,y,z,data[:,4]])\n",
    "    return cart_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5fcb687-54da-4d49-a998-d530c79b039e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_cm(data):\n",
    "    #print(\"this should be my cartesian data...\")\n",
    "    #print(data)\n",
    "    #print(\"and the shape of the data is:\\t\", data.shape)\n",
    "    positions = data[:,2:5]\n",
    "    #print(\"positions\")\n",
    "    #print(positions)\n",
    "    masses = data[:,1]\n",
    "    #print(\"masses\")\n",
    "    #print(masses)\n",
    "    #print(data.shape[0])\n",
    "    sum_mass = (np.repeat(np.sum(masses),data.shape[0])).reshape(-1,1)\n",
    "    #print(\"shape of sum masses:\\t\", sum_mass.shape)\n",
    "    cm = np.sum(positions.T * masses, axis=1) / np.sum(masses)\n",
    "    #cm = cm.reshape(-1,3)\n",
    "    cm_x = (np.repeat(cm[0],data.shape[0])).reshape(-1,1)\n",
    "    cm_y = (np.repeat(cm[1],data.shape[0])).reshape(-1,1)\n",
    "    cm_z = (np.repeat(cm[2],data.shape[0])).reshape(-1,1)\n",
    "    #print(\"cm\",cm)\n",
    "    time = data[np.argmax(data[:,1],axis=0),5]\n",
    "    time = (np.repeat(time,data.shape[0])).reshape(-1,1)\n",
    "    index_evt = (data[:,0]).reshape(-1,1)\n",
    "    #print(\"shape of data[:,0]:\\t\", index_evt.shape)\n",
    "    #print(\"shape of sum_mass:\\t\", sum_mass.shape)\n",
    "    #print(\"shape of cm_x:\\t\", cm_x.shape)\n",
    "    #print(\"shape of cm_y:\\t\", cm_y.shape)\n",
    "    #print(\"shape of cm_z:\\t\", cm_z.shape)\n",
    "    #print(\"shape of time:\\t\", time.shape)\n",
    "    arr_cart = np.concatenate((index_evt,sum_mass,cm_x,cm_y,cm_z,time), axis=1)\n",
    "    #print(\"incoming data struc:\")\n",
    "    #print(data)\n",
    "    #print(\"outgoing cms data:\")\n",
    "    #print(arr_cart)\n",
    "    return arr_cart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1349297a-1a00-47b8-9aae-aff8c760b307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cart2sph(data):\n",
    "    x = data[:,2]\n",
    "    y = data[:,3]\n",
    "    z = data[:,4]\n",
    "    hxy = np.hypot(x, y)\n",
    "    r = np.hypot(hxy, z)\n",
    "    th = ((np.arccos(z/r))/math.pi)*180\n",
    "    az = ((np.arctan2(y,x))/math.pi)*180 \n",
    "    az[az < 0] += 360\n",
    "    return_arr = np.array([data[:,0],data[:,1],th,az,data[:,5]]).T\n",
    "    return return_arr\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "619f6fa5-1e28-4276-9e84-c4ee410d4eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_reco_to_file_cms(data,reco_vals):\n",
    "    #print(\"reco_vals\",reco_vals)\n",
    "    ene_list = []\n",
    "    ene_true_list = []\n",
    "    idx = 0\n",
    "    array_unique_events = np.unique(data[:,0])\n",
    "    fmt = '%i','%1.5f', '%1.5f','%1.5f','%1.2f' \n",
    "    with open('test_file_agllo_13_02.txt', 'w') as f:\n",
    "        for i in range(0,int(np.max(data,axis=0)[0]+1)-(int(np.max(data,axis=0)[0]+1)%3) ,3):\n",
    "        #for i in range(0,int(np.max(data,axis=0)[0])-(int(np.max(data,axis=0)[0])%3) ,3):\n",
    "            mask = ((data[:,0] == i) | (data[:,0] == i+1) | (data[:,0] == i+2))\n",
    "            evt = data[mask]\n",
    "            evt[:,4] = evt[:,4] - 4500\n",
    "            pair_indices = list(combinations(range(evt.shape[0]), 2))\n",
    "            ##pair indices which belong together...\n",
    "            pred_comb = []\n",
    "            ##TJ this is the new part with true stuff\n",
    "            true_comb = []\n",
    "            for m in range(evt.shape[0]):\n",
    "                pred_comb.append((m,m))\n",
    "                true_comb.append((m,m))\n",
    "            for j in range (len(pair_indices)):\n",
    "                #print(\"reco_vals[idx+j]:\\t\", reco_vals[idx+j])\n",
    "                if reco_vals[idx+j] > 0.75:\n",
    "                    pred_comb.append(pair_indices[j])\n",
    "            G = nx.Graph()\n",
    "            G.add_edges_from(pred_comb)\n",
    "            connected_components = list(nx.connected_components(G))\n",
    "            set_pred = {frozenset(sublist) for sublist in connected_components}\n",
    "            #print(\"set_pred\", set_pred)\n",
    "            #print(\"connected components:\\t\", connected_components)\n",
    "            for k in range(len(connected_components)):\n",
    "                ## do cms for all clustered hits and write everything to file\n",
    "                cluster_data = evt[list(connected_components[k]),:]\n",
    "                #print(cluster_data)\n",
    "                cluster_data_cart = sph2cart(cluster_data)\n",
    "                #print(\"cartesian data\")\n",
    "                #print(cluster_data_cart)\n",
    "                cluster_data_cart_cms = func_cm(cluster_data_cart)\n",
    "                cluster_data_sph_cms = cart2sph(cluster_data_cart_cms)\n",
    "                #print(\"this is the shape of the data I want to store in file:\",cluster_data_sph_cms.shape)\n",
    "                #now write to file..\n",
    "                #print(\"data shape...\",data.shape)\n",
    "                for l in range(cluster_data_sph_cms.shape[0]):\n",
    "                    #print(\"llll:\\t\",l)\n",
    "                    np.savetxt(f,cluster_data_sph_cms[l,:].reshape(1,-1),fmt = fmt,delimiter=\",\")\n",
    "            idx += len(pair_indices)\n",
    "    f.close()\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddda32cc-3732-430e-94f8-715fdf452d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def check_matrix(f_set1, f_set2):\n",
    "    #print(\"input true:\\t\", f_set1)\n",
    "    #print(\"input pred:\\t\", f_set2)\n",
    "    set1 = copy.deepcopy(f_set1)\n",
    "    set2 = copy.deepcopy(f_set2)\n",
    "    #logic here inside\n",
    "    # Remove identical frozensets\n",
    "    common = set1 & set2\n",
    "    set1 -= common\n",
    "    set2 -= common\n",
    "\n",
    "    # Step 2: Remove subsets from set1 if they are subsets of elements in set2\n",
    "    set1 = {s1 for s1 in set1 if not any(s1.issubset(s2) for s2 in set2)}\n",
    "\n",
    "    # Step 3: Remove subsets from set2 if they are subsets of elements in set1\n",
    "    set2 = {s2 for s2 in set2 if not any(s2.issubset(s1) for s1 in set1)}\n",
    "\n",
    "    #print(\"Length of set1:\\t\", len(set1))\n",
    "    #print(\"Length of set2:\\t\", len(set2))\n",
    "\n",
    "    # Final result\n",
    "    #print(\"Updated set1:\", set1)\n",
    "    #print(\"Updated set2:\", set2)\n",
    "\n",
    "    if (len(set1) == 0 and len(set2) == 0):\n",
    "        return  \"t\"\n",
    "    if (len(set1) == 0 and len(set2) != 0):\n",
    "        return \"fp\"\n",
    "    if (len(set1) != 0 and len(set2) == 0):\n",
    "        return \"fn\"\n",
    "    if (len(set1) != 0 and len(set2) != 0):\n",
    "        return \"fpfn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f55aa66-5854-44c0-96a2-6721d7abde21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

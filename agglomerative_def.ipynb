{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5087130a-0f32-4e94-8d0d-ee8610668a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "from itertools import combinations\n",
    "import torch\n",
    "import math \n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import fclusterdata\n",
    "import networkx as nx\n",
    "%run r3b_clustering_def.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d08fdee8-8d0a-4a1c-a163-5d8066d94bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_sph_to_cart(arr):\n",
    "    ##input data has columns eventnr, energy, theta, phi, hit-time\n",
    "    r = arr[:,4]*2.5\n",
    "    energy = arr[:,1]\n",
    "    theta = arr[:,2]\n",
    "    phi = arr[:,3]\n",
    "    rsin_theta = r*np.sin(theta)\n",
    "    x = rsin_theta*np.cos(phi)\n",
    "    y = rsin_theta*np.sin(phi)\n",
    "    z = r*np.cos(theta)\n",
    "    cart_arr = np.concatenate((x.reshape(-1,1),y.reshape(-1,1),z.reshape(-1,1),energy.reshape(-1,1)), axis=1)\n",
    "    return cart_arr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0ff274d-3cf0-4fff-b875-890e9a3c6843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(xss):\n",
    "    return [x for xs in xss for x in xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b25780f1-70c3-4053-9cfd-07b1e6c6fc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agglo_clustering(data,threshold):\n",
    "    array_unique_events = np.unique(data[:,0])\n",
    "    all_pred = []\n",
    "    print(int(np.max(data,axis=0)[0])-(int(np.max(data,axis=0)[0])%3))\n",
    "    for i in range(0,int(np.max(data,axis=0)[0]+1)-(int(np.max(data,axis=0)[0]+1)%3) ,3):\n",
    "    #for i in range(0,int(np.max(data,axis=0)[0])-(int(np.max(data,axis=0)[0])%3) ,3):\n",
    "        if i % 1000 == 0:\n",
    "                percentage = (i /int(np.max(data,axis=0)[0]+1)) * 100\n",
    "                print(f\"Progress: {percentage:.2f}%\")\n",
    "        #print(\"unique stuff:\\t\",array_unique_events[i+2])\n",
    "        evt = data[data[:,0] == array_unique_events[i]]\n",
    "        evt = np.vstack((evt,data[data[:,0] == array_unique_events[i+1]]))\n",
    "        evt = np.vstack((evt,data[data[:,0] == array_unique_events[i+2]]))\n",
    "        nr_hits = evt.shape[0]\n",
    "        hitnr = np.array([x for x in range(evt.shape[0])])\n",
    "        hitnr = np.transpose(hitnr)\n",
    "        hitnr = hitnr.reshape(-1, 1)\n",
    "        ### transform event from  eventnr, energy, theta, phi, hit-time to 'x','y','z','energy'\n",
    "        evt_cart = df_sph_to_cart(evt)\n",
    "        ### insert agglomerative algorithm\n",
    "        output = fclusterdata(evt_cart, t=threshold, criterion='distance',method=\"ward\")\n",
    "        #print(output)\n",
    "        output = np.reshape(output,(-1,1))\n",
    "        output = output.astype(int)\n",
    "        evt = np.append(evt,output,axis=1)\n",
    "        nr_reco_cluster = np.max(output)\n",
    "        cluster_list = []\n",
    "        for i in range(1,nr_reco_cluster+1):\n",
    "            subl = []\n",
    "            for j in range(evt.shape[0]):\n",
    "                if (evt[j,5] == i):\n",
    "                    subl.append(j)\n",
    "            cluster_list.append(subl)        \n",
    "        #compress list of clusters, they need at least two entries to be a cluster, otherwise the single hit is treated as cluster\n",
    "        compr_cluster_list = []\n",
    "        for i in range(len(cluster_list)):\n",
    "            if len(cluster_list[i]) > 1:\n",
    "                compr_cluster_list.append(cluster_list[i])\n",
    "            else:\n",
    "                continue\n",
    "        final_pair_list = []\n",
    "        for i in range(len(compr_cluster_list)):\n",
    "            pair_indices = list(combinations(compr_cluster_list[i],2))\n",
    "            final_pair_list.append(pair_indices)\n",
    "        reco_indices = flatten(final_pair_list)\n",
    "        \n",
    "        # compare all combinations with all predicted combinations\n",
    "        all_combinations = list(combinations(range(nr_hits), 2))\n",
    "        ## predictions\n",
    "        pred_list = []\n",
    "        for i in range(len(all_combinations)):\n",
    "            pred_value = 0\n",
    "            for j in range(len(reco_indices)):\n",
    "                if (all_combinations[i] == reco_indices[j]):\n",
    "                    pred_value = 1\n",
    "            pred_list.append(pred_value)\n",
    "            all_pred.append(pred_value)\n",
    "    return all_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04a8e684-4d23-437c-b0e2-4fd428af4d8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #data = genfromtxt('raw_data_test.txt', delimiter=',')\n",
    "# #data = genfromtxt('data_raw_uniform_test.csv', delimiter=',')\n",
    "# #data = genfromtxt('data_stream_2121.txt', delimiter=',')\n",
    "# data = genfromtxt('demo_file.txt', delimiter=',')\n",
    "# data[:,4] = data[:,4]+4500  #this step is needed, I only want positive time values, so that I can use the time as a radius\n",
    "# #my_data[:,4] = 1  #this step is needed, I only want positive time values, so that I can use the time as a radius\n",
    "\n",
    "\n",
    "\n",
    "# # ### structure of mydata : eventnr, energy, theta, phi, hit-time\n",
    "# data = data*[1.,1.,3.14159/180,3.14159/180,1.]\n",
    "# unique_values, continuous_numbers = np.unique(data[:,0], return_inverse=True)\n",
    "# data[:,0] = continuous_numbers\n",
    "# print(data)\n",
    "# out_cluster_agglo = run_agglo_clustering(data,3540)\n",
    "# #foo = plot_true_reco(data)\n",
    "# foo_comb = get_true_combinatorics(data)\n",
    "# print(\"data size:\", len(out_cluster_agglo))\n",
    "# print(\"true_size:\",len(foo_comb))\n",
    "# print(\"type of out_cluster_agglo:\",type(out_cluster_agglo))\n",
    "# print(\"and this is out_cluster_agglo\", out_cluster_agglo)\n",
    "# foo_ene = get_true_reco_ene(data,out_cluster_agglo,foo_comb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc3dcd9-fd9d-4d38-895c-3707bdcd23a3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efba913-2ef4-408c-a100-1b6af77dab3c",
   "metadata": {},
   "source": [
    "### test from here if I can write clustered data to file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cafcddb-93d1-47d4-84ca-f0ba654aa654",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write_reco_to_file_cms(data,out_cluster_agglo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d48539-8eb1-42b2-a54c-f470f1f9c466",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e215544-6618-4cbb-8924-161f3a1c3012",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
